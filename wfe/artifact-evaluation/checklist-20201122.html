<i>[&nbsp;<a href="$#ck_root_page_url#$submission$#ck_page_suffix#$">Back to the submission guide</a>&nbsp;]</i>

<!-------------------------------------------------------------------------------------------->
<p>
<h1><a name="extended">Artifact Checklist (V20201122)</a></h1>

<div style="margin-left: 20px;">

  Here we provide a few informal suggestions to help you fill in your <a href="https://github.com/ctuning/ck-artifact-evaluation/blob/master/wfe/artifact-evaluation/templates/ae.tex">Artifact Appendix with the Reproducibility Checklist</a> 
  for submission while avoiding common pitfalls.  

</div>

<!-------------------------------------------------------------------------------------------->
<div style="margin-left: 20px;">

 <!------------------------------------------------------------------->
 <h2><a name="desc_abstract">Abstract</a></h2>

  Briefly and informally describe your artifact including minimal hardware and software requirements, 
  how it supports your paper, how it can be validated, and what is the expected result. It will be used
  to select appropriate reviewers.
  It will also help readers understand what was evaluated and how.

 <!------------------------------------------------------------------->
 <h2>Checklist</h2>

     Together with the artifact abstract, this check-list will help us make sure that reviewers 
     have appropriate competency and an access to the technology required to evaluate your artifact. 
     It can also be used as meta information to find your artifacts in Digital Libraries.

     <img src="$#ck_url_template_pull#$resources/image-general-workflow1.png" align="left" style="margin:10px;margin-right:30px;">
     <br><br>

     Fill in whatever is applicable with some informal keywords and remove unrelated items 
     (please consider questions below just as informal hints
     that reviewers are usually concerned about):

     <div style="margin-left: 120px;">
      <ul>
       <li>
        <b>Algorithm:</b> Are you presenting a new algorithm?
       </li>
       <li>
        <b>Program:</b> Which benchmarks do you use 
                       (<a href="http://parsec.cs.princeton.edu">PARSEC</a>
                        <a href="https://github.com/ctuning/ck-wa">ARM real workloads</a>,
                        <a href="http://www.nas.nasa.gov/publications/npb.html">NAS</a>,
                        <a href="https://www.eembc.org">EEMBC</a>,
                        <a href="http://www.capsl.udel.edu/splash/index.html">SPLASH</a>,
                        <a href="https://www.cs.virginia.edu/~skadron/wiki/rodinia">Rodinia</a>,
                        <a href="http://www.netlib.org/linpack">LINPACK</a>,
                        <a href="http://hpcg-benchmark.org/">HPCG</a>,
                        <a href="http://wwweb.eecs.umich.edu/mibench">MiBench</a>,
                        <a href="https://www.spec.org/cpu2006">SPEC</a>,
                        <a href="http://github.com/ctuning/ctuning-programs">cTuning</a>, etc)? 
                        Are they included or should they be downloaded? Which version?
                        Are they public or private? If they are private, 
                        is there a public analog to evaluate your artifact?
                        What is the approximate size?
       </li>
       <li>
        <b>Compilation:</b> Do you require a specific compiler? Public/private? Is it included? Which version? 
       </li>
       <li>
        <b>Transformations:</b> Do you require a program transformation tool (source-to-source, binary-to-binary, compiler pass, etc)? 
                                Public/private? Is it included? Which version?
       </li>
       <li>
        <b>Binary:</b>          Are binaries included? OS-specific? Which version?
       </li>
       <li>
        <b>Model:</b>           Do you use specific models (ImageNet, AlexNet, MobileNets)?
                                Are they included? If not, how to download and install? 
                                What is their approximate size?
       </li>
       <li>
        <b>Data set:</b>        Do you use specific data sets?
                                Are they included? If not, how to download and install? 
                                What is their approximate size?
       </li>
       <li>
        <b>Run-time environment:</b> Is your artifact OS-specific (Linux, Windows, MacOS, Android, etc) ?
                                     Which version? Which are the main software dependencies (JIT, libs, run-time adaptation frameworks, etc);
                                     Do you need root access? 
       </li>
       <li>
        <b>Hardware:</b>             Do you need specific hardware (supercomputer, architecture simulator, CPU, GPU, neural network accelerator, FPGA) 
                                     or specific features (hardware counters
                                     to measure power consumption, SUDO access to CPU/GPU frequency, etc)? 
                                     Are they publicly available?
       </li>
       <li>
        <b>Run-time state:</b>       Is your artifact sensitive to run-time state (cold/hot cache, network/cache contentions, etc.)
       </li>
       <li>
        <b>Execution:</b>            Any specific conditions should be met during experiments (sole user, process pinning, profiling, adaptation, etc)? How long will it approximately run?
       </li>
       <li>
        <b>Metrics:</b>              Which metrics are reported (execution time, inference per second, Top1 accuracy, static and dynamic energy consumption, etc) - 
                                     particularly important for multi-objective benchmarking, optimization and co-design 
                                     (see <a href="https://cKnowledge.org/request">ACM ReQuEST ML/SW/HW co-design tournaments</a>).
       </li>
       <li>
        <b>Output:</b>               What is your output (console, file, table, graph) and what is your result 
                                     (exact output, numerical results, measured characteristics, etc)?
                                     Is expected result included?

       </li>
       <li>
        <b>Experiments:</b>          How to prepare experiments and replicate/reproduce results
                                     (OS scripts, manual steps by user, 
                                     <a href="https://jupyter.org">IPython/Jupyter notebook</a>, 
                                     <a href="https://cKnowledge.io/?q=%22reproduced-papers%22%20AND%20%22portable-workflow-ck%22">automated workflows</a>, etc)? 
                                     Do not forget to mention the maximum allowable variation of empirical results!
       </li>

       <li>
        <b>How much disk space required (approximately)?:</b> This can help evaluators and end-users to find appropriate resources.
       </li>

       <li>
        <b>How much time is needed to prepare workflow (approximately)?:</b> This can help evaluators and end-users to estimate resources needed to evaluate your artifact.

       </li>

       <li>
        <b>How much time is needed to complete experiments (approximately)?:</b> This can help evaluators and end-users to estimate resources needed to evaluate your artifact.

       </li>

       <li>
        <b>Publicly available?:</b>  Will your artifact be publicly available? If yes, we may spend an extra effort to help you with the documentation.
       </li>

       <li>
        <b>Code licenses (if publicly available)?:</b> If you workflows and artifacts will be publicly available, please provide information about licenses.
                                                            This will help the community to reuse your components.
       </li>

       <li>
        <b>Code licenses (if publicly available)?:</b> If you workflows and artifacts will be publicly available, please provide information about licenses.
                                                            This will help the community to reuse your components.
       </li>

       <li>
        <b>Workflow frameworks used?</b>   Did authors use any workflow framework which can automate and customize experiments?
       </li>

       <li>
        <b>Archived?:</b> 
        Note that the author-created artifacts relevant to this paper 
        will receive the ACM "artifact available" badge *only if* 
        they have been placed on a publicly 
        accessible archival repository such as <a href="https://zenodo.org">Zenodo</a>, 
        <a href="https://figshare.com">FigShare</a>
        or <a href="http://datadryad.org">Dryad</a>. 
        A DOI will be then assigned to their artifacts and must be provided here!  
        Personal web pages, Google Drive, GitHub, GitLab and BitBucket 
        are not accepted for this badge. 
        Authors can provide this link at the end of the evaluation.
       </li>
      </ul>

     </div>

<!------------------------------------------------------------------->
 <h2><a name="desc_description">Description</a></h2>
  <div style="margin-left: 20px;">

   <h3>How to access</h3>

     Describe, how reviewers can access your artifact:
     <ul>
      <li>Clone repository from GitHub, GitLab, BitBucket or any similar service</li>
      <li>Download package from a public website</li>
      <li>Download package from a private website (you will need to send information how to access your artifact to AE chairs)</li>
      <li>Access artifact via private machine with pre-installed software (only when access to rare hardware is required or proprietary
           software is used - you will need to send information and credentials to access your machine to the AE chairs)</li>
     </ul>

     Please describe approximate disk space required after unpacking your artifact 
     (to avoid surprises when artifact requires 20GB of free space). We do not have
     a strict limit but strongly suggest to limit the space to several GB 
     and avoid including unnecessary software packages to your VM images.

<!------------------------------------------------------------------->
   <h3>Hardware dependencies</h3>

    Describe any specific hardware and specific features
    required to evaluate your artifact 
    (vendor, CPU/GPU/FPGA, number of processors/cores, interconnect, memory, 
    hardware counters, etc).

<!------------------------------------------------------------------->
   <h3>Software dependencies</h3>

    Describe any specific OS and software packages required to evaluate your
    artifact. This is particularly important if you share your source code 
    and it must be compiled or if you rely on some proprietary software that you
    can not include to your package. In such case, we strongly suggest you 
    to describe how to obtain and to install all third-party software, data sets
    and models.

    <br><br>
    <i>Note that we are trying to obtain AE licenses for some commonly used proprietary tools and benchmarks 
    - you will be informed in case of positive outcome.</i>


<!------------------------------------------------------------------->
   <h3>Data sets</h3>

    If third-party data sets are not included in your packages (for example, 
    they are very large or proprietary), please provide details about how to download
    and install them. 

    <i>In case of proprietary data sets, we suggest you provide reviewers
    a public alternative subset for evaluation</i>.

<!------------------------------------------------------------------->
   <h3>Models</h3>

    If third-party models are not included in your packages (for example, 
    they are very large or proprietary), please provide details about how to download
    and install them. 

  </div>

<!------------------------------------------------------------------->
 <p>
 <h2><a name="desc_installation">Installation</a></h2>

 Describe the setup procedures for your artifact 
 targeting novice users
 (even if you use VM image or access to remote machine) . 

<!------------------------------------------------------------------->
 <p>
 <h2><a name="desc_workflow">Experiment workflow</a></h2>

  Describe the experimental workflow and how it is implemented, 
  invoked and customized (if needed), i.e. some OS scripts, 
  <a href="https://jupyter.org">IPython/Jupyter notebook</a>, 
  <a href="https://github.com/ctuning/ck/wiki/Adding-new-workflows">portable CK workflow</a>, etc.

  See <a href="https://cKnowledge.io/reproduced-papers">past reproduced papers</a>
  and an example of the experimental workflow 
  for multi-objective and machine-learning based autotuning:

  <p>
  <center>
  <img src="$#ck_url_template_pull#$resources/image-pipelines2.png"><br><br>
  </center>

<!------------------------------------------------------------------->
 <p>
 <h2><a name="desc_evaluation">Evaluation and expected result</a></h2>

  Describe all the steps necessary to reproduce the key results from your paper. 
  Describe the expected result and the maximum allowable variation
  of empirical results (particularly important for performance numbers and speed-ups).
  See the <a href="https://www.sigplan.org/Resources/EmpiricalEvaluation">SIGPLAN Empirical Evaluation Guidelines</a>,
  the <a href="https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist.pdf">NeurIPS reproducibility checklist</a>
  and the <a href="$#ck_root_page_url#$faq$#ck_page_suffix#$">AE FAQ</a>.

<!------------------------------------------------------------------->
 <p>
 <h2><a name="desc_evaluation">Experiment customization</a></h2>

  It is currently optional since it is not always trivial.
  If possible, describe how to customize your workflow, i.e. if 
  it is possible to use different data sets, benchmarks, real applications,
  predictive models, software environment (compilers, libraries, 
  run-time systems), hardware, etc. Also, describe if it is possible 
  to parameterize your workflow (whatever is applicable such as 
  changing number of threads, applying different optimizations, CPU/GPU frequency, 
  autotuning scenario, model topology, etc). 

<!------------------------------------------------------------------->
 <p>
 <h2>Notes</h2>

 You can add informal notes to draw the attention of reviewers
 about specific requirements to evaluate your artifact.

</div>

<hr>
  After introducing the unifed artifact appendix and checklist in 2015, we continue updating it
  based on public <a href="https://www.reddit.com/r/MachineLearning/comments/ioq8do/n_reproducing_150_research_papers_the_problems">discussions</a>,
  <a href="prior_ae.html">past Artifact Evaluation experience</a>,
  <a href="https://docs.google.com/document/d/1QZzRVMZMsMev3lxBgHG4TFHEFXy__N7B69ysWXi0ZcY/edit">the feedback from researchers</a>,
  <a href="http://artifact-eval.org">PL AE</a>, 
  and the <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current">ACM reviewing and badging policy</a>.
  Our goal is to come up with a common methodology, <a href="submission_extra.html">unified artifact appendix with the reproducibility checklist</a>
  and an <a href="https://cKnowledge.io">open reproducibility platform</a> for artifact sharing, validation and reuse.
  If you have questions or suggestions, do not hesitate to get in touch with the AE community using 
  the <a href="https://groups.google.com/forum/#!forum/artifact-evaluation">dedicated AE google group</a>.


<br>
<br>
<center>
 <small>
  <i>
   This document was prepared by <a href="https://cKnowledge.io/@gfursin">Grigori Fursin</a>
   with contributions from <a href="https://people.cs.pitt.edu/~childers">Bruce Childers</a>, 
   <a href="https://www.sandia.gov/~maherou">Michael Heroux</a>, 
   <a href="https://gcl.cis.udel.edu/personal/taufer/">Michela Taufer</a> and other colleagues.
  </i>
 </small>
</center>

<br>
