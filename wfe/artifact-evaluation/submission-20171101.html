<b>News:</b><br>
<ul>
 <li>
  <b>Do not forget to provide a list of hardware, software, benchmark and data set dependencies in your artifact abstract - this is essential to find appropriate evaluators!</b>
 </li>
 <li>
  Participate in the <a href="http://cKnowledge.org/request">1st competition on reproducible SW/HW co-design competition</a> 
  at ASPLOS'18 (submission template with Artifact Appendix is available <a href="http://cKnowledge.org/request-template.tex">here</a>).
 </li>
 <li>
  For SC'17 authors: you can find extra notes about how to fill in Artifact Appendix <a href="$#ck_root_page_url#$submission_extra$#ck_page_suffix#$">here</a>.
 </li>
 <li>
  Slides from the CGO/PPoPP'17 AE discussion session on how to improve artifact evaluation are available <a href="https://www.slideshare.net/GrigoriFursin/cgoppopp17-artifact-evaluation-discussion-enabling-open-and-reproducible-research">here</a>.
 </li>
 <li>
  We co-authored a new <a href="http://www.acm.org/publications/policies/artifact-review-badging">ACM Result and Artifact Review and Badging policy</a> in 2016 and now use it for the CGO and PPoPP AE</a>.
 </li>
</ul>

<br>
This guide (V20171101) was prepared by <a href="https://cknow.io/@gfursin">Grigori Fursin</a>
and <a href="http://people.cs.pitt.edu/~childers">Bruce Childers</a> with contributions from 
<a href="http://www.sandia.gov/~maherou">Michael Heroux</a>, 
<a href="https://gcl.cis.udel.edu/personal/taufer/">Michela Taufer</a> 
and other <a href="$#ck_root_page_url#$committee$#ck_page_suffix#$">colleagues</a>
to help you describe and submit your artifacts for evaluation across a range of CS conferences
and journals.


It gradually evolves based on <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IwcnpkwAAAAJ&cstart=20&citation_for_view=IwcnpkwAAAAJ:isC4tDSrTZIC">our long-term vision</a>
and your feedback during our <a href="https://www.slideshare.net/GrigoriFursin/cgoppopp17-artifact-evaluation-discussion-enabling-open-and-reproducible-research">public Artifact Evaluation discussion sessions</a>.

<p>
<b>Navigation</b>:
<ul>
 <li><a href="#expect">What to expect</a></li>
 <li><a href="#prepare">Preparing artifacts for submission</a></li>
 <li><a href="#accepted">If accepted</a></li>
 <li><a href="#examples">Examples of accepted artifacts</a></li>
 <li><a href="#archive">Methodology archive</a></li>
 <li><a href="$#ck_root_page_url#$submission_extra$#ck_page_suffix#$">Extended artifact description</a></li>
</ul>

<!-------------------------------------------------------------------------------------------->
<p>
<h1><a name="expect"><u>What to expect</u></a></h1>

<p>
We aim to formalize and unify artifact submission while keeping it as simple as possible.
You will need to pack your artifacts (code and data) using any publicly available tool
you prefer. In some exceptional cases when rare hardware or proprietary software is used,
you can arrange a remote access to a machine with the pre-installed software.
We strongly encourage to use workflow frameworks such as <a href="http://cKnowledge.org">CK</a>
to unify preparation and validation of experiments (ACM currently <a href="https://dl.acm.org/reproducibility.cfm">evaluates possibility to
integrate CK</a> with the ACM Digital Library; <a href="http://cTuning.org">cTuning foundation</a>
also provides free community help to convert your artifacts to the CK format</a>).

<p>
Then you need to prepare a small and informal Artifact Evaluation appendix
using our <a href="$#ck_url_template_pull#$templates/ae-20170622.tex">AE LaTeX template</a> (now used by CGO, PPoPP, SuperComputing, PACT, IA3, RTSS and other ACM/IEEE conferences and workshops) 
to explain evaluators what your artifacts are and how to use them
(you will be allowed to add up to 2 pages of this Appendix to your final camera-ready paper).
You can find examples of such AE appendices in the following papers:
<a href="https://www.cl.cam.ac.uk/~sa614/papers/Software-Prefetching-CGO2017.pdf">CGO'17</a>, 
<a href="http://arxiv.org/pdf/1501.05387v6.pdf">PPoPP'16</a>,
<a href="https://drive.google.com/file/d/0BxJn2NuLIEx_dnRlSHU3MlpHSGs/view">SC'16</a>.

<p>
At least three reviewers will follow your guide to evaluate your artifacts and will then send you a report 
with the following overall assessment of your artifact based 
on our <a href="$#ck_root_page_url#$reviewing$#ck_page_suffix#$">reviewing guidelines</a>:

<ul>
 <li>
  <b>exceeded expectations</b>
 </li>
 <li>
  <b>met expectations </b>
 </li>
 <li>
  <b>fell below expectations</b>
 </li>
</ul>

where <b>"met expectations" score or above</b> means that your artifact 
successfully passed evaluation and will receive the following stamps of approval 
depending on the conference:


<center>
   <table border="1" cellpadding="5" cellspacing="0">
    <tr>
     <td align="center"><b><a href="http://www.acm.org/publications/policies/artifact-review-badging">Badges for ACM conferences</a><br>(CGO,PPoPP,SC)</b></td>
     <td align="center"><b>Badges for non-ACM conferences<br>(PACT)</b></td>
    </tr>

    <tr>
     <td valign="top" align="center">
      Check <a href="$#ck_root_page_url#$reviewing$#ck_page_suffix#$">our AE criteria</a>:

      <p><b>Artifacts Evaluated - Functional</b><br>
      <img src="http://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_functional_dl.jpg">

      <p><b>Artifacts Evaluated - Reusable</b><br>
      <img src="http://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_reusable_dl.jpg">

      <p><b>Artifacts Available</b><br>
      <img src="http://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_available_dl.jpg">

      <p><b>Results validated</b><br>
      <img src="http://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/results_reproduced_dl.jpg">

     </td>
     <td valign="top" align="center">

     <center><img src="$#ck_url_template_pull#$resources/ae-stamp-pact.png"></center>

     </td>
    </tr>
   </table>
</center>

<p>
The highest ranked artifact which is not only reproducible 
but also easily customizable and reusable typically 
receives a <i>"distinguished artifact" award</i>.

<p>
Since our eventual goal is to promote <a href="http://dl.acm.org/citation.cfm?id=2618142">collaborative and reproducible research</a>, 
we see AE as a cooperative process between authors 
and reviewers to validate shared artifacts (rather than naming and shaming
problematic artifacts). Therefore, we allow communication between authors
and reviewers to fix raised issues until a given artifact can pass evaluation
(unless a major problem is encountered).

In such cases, AE chairs will serve as a proxy to avoid 
revealing reviewers' identity (reviews are blind,
i.e. your identity is known to reviewers since your paper 
is already accepted, but not vice versa).

<!-------------------------------------------------------------------------------------------->
<p>
<h1><a name="prepare"><u>Preparing artifacts for submission</u></a></h1>

You need to perform the following steps to submit your artifact for evaluation:

<ol>
 <li>
  <b>Prepare experimental workflow</b>.

  <p><i>Note that if you just want to make your artifacts publicly available
  (which is also encouraged) without validation of experimental results, please go to the next step</i>.

  <p>We strongly encourage you to at least provide some scripts to prepare and run experiments,
  as well as reporting and validating results. You may be interested to use 
  <a href="http://jupyter.org">Jupyter Notebooks</a> for this purpose.

  <p>
  Furthermore, from our <a href="https://www.slideshare.net/GrigoriFursin/enabling-open-and-reproducible-computer-systems-research-the-good-the-bad-and-the-ugly">past Artifact Evaluation experience</a>, 
  we have noticed that the biggest burden for evaluators is to deal with numerous ad-hoc scripts to prepare, customize and run experiments,
  try other benchmarks, data sets, compilers and simulators, analyze results and compare them with the ones from the paper. 
  That's why we collaborate with <a href="http://acm.org">ACM</a> to unify packing and sharing of artifacts as reusable and customizable components
  using the <a href="http://cKnowledge.org">Collective Knowledge framework</a> and <a href="https://occam.cs.pitt.edu">OCCAM</a>
  (see <a href="https://dl.acm.org/docs/reproducibility.cfm">ACM announcement</a>).
  You are not obliged to use CK and OCCAM since they may only influence "Artifacts Evaluated - Reusable" badge 
  but not the overall evaluation. However if you are interested to try CK, 
  <a href="http://cTuning.org">cTuning foundation</a> 
  offers free help to convert your workflows
  to the CK format while reusing 
  <a href="https://github.com/ctuning/ck/wiki/Shared-repos#user-content-shared-workflows">a growing number of open CK artifacts</a>.
  Feel free to contact <a href="mailto:Grigori.Fursin@cTuning.org">Grigori Fursin</a> 
  as soon as possible for more details. <b>The highest ranked artifacts shared in the CK format
  will also receive a 300$ Amazon gift card from <a href="http://dividiti.com">dividiti</a></b>.
  Check out the following artifacts which shared 
  using CK framework:  <a href="https://www.cl.cam.ac.uk/~sa614/papers/Software-Prefetching-CGO2017.pdf">CGO'17 paper</a>,
  <a href="https://dl.acm.org/citation.cfm?doid=3149704.3149768">IA3 @ SuperComputing'17 paper</a>,
  <a href="https://dl.acm.org/citation.cfm?doid=2807591.2807619">SuperComputing'15 paper</a>, etc .

  <p>
 <li>
  <b>Pack your artifact</b> (code and data) or provide an easy access to them 
  using any publicly available and free tool you prefer or strictly require. 
  <br>
  <br>
  For example, you can use the following:
  <ul>
   <li>
    <a href="https://www.virtualbox.org">Virtual Box</a> to pack all code and data including OS 
    (typical images are around 2..3GB; we strongly recommend to avoid images larger than 10GB).
   </li>
   <li>
    <a href="https://www.docker.com">Docker</a> to pack only touched code and data during experiment. 
   </li>
   <li>
    Standard zip or tar with all related code and data, particularly when an artifact
    should be rebuilt on a reviewers machine (for example to have a non-virtualized access to a specific hardware). 
    You may check <a href="https://www.reprozip.org">ReproZip</a> tool to automatically pack your artifacts with all dependencies.
   </li>
   <li>
    Private or public GIT or SVN.
   </li>
   <li>
    Arrange a remote access to a machine with pre-installed software 
    (<i>exceptional cases when rare hardware or proprietary software is used or your VM image is too large)</i>) 
    - you will need to privately send the access information to the AE chairs. Also, please avoid making any changes
    to the remote machine during evaluation unless explicitly agreed with AE chairs - you can do it during
    the rebuttal phase if needed!
   </li>
   <li>
    Check <a href="http://github.com/ctuning/ck/wiki/Enabling-open-science-tools">other tools</a> 
    which can be useful for artifact and workflow sharing.
  </ul>

  <br>

 <li>
  <b>Write a brief artifact abstract with a SW/HW check-list</b> to informally describe your artifact 
  including minimal hardware and software requirements, how it supports your paper, how it can be validated and
  what the expected result is. It will be used to select appropriate reviewers.
 </li>
 
 <br>
 <li>
  <b>Fill in and append AE template (<a href="$#ck_url_template_pull#$templates/ae-20170622.tex">download here</a>)</b> to the PDF of your accepted paper.
  Though it should be relatively intuitive, we still strongly suggest you to
  check out <a href="$#ck_root_page_url#$submission_extra$#ck_page_suffix#$">extra notes
  about how to fill in this template</a> based on our past AE experience.
 </li>

 <br>
 <li>
  <b>Submit artifact abstract and the new PDF </b> at the AE submission website depending on a conference.
 </li>

</ol>

<i>
If you encounter problems, find some ambiguities or have any questions, 
do not hesitate to contact <a href="mailto:Grigori.Fursin@cTuning.org;childers@cs.pitt.edu">AE steering committee</a>!
</i>

<!-------------------------------------------------------------------------------------------->
<p>
<h1><a name="accepted"><u>If accepted</u></a></h1>

 AE chairs will tell you how to add appropriate stamps to the final camera-ready version of your paper.
 We also strongly encourage you to add up to 2 pages of your AE appendix 
 to your camera ready paper while removing all unnecessary or confidential information. 
 This will help readers better understand what was evaluated.

 <p>
 Though you are not obliged to publicly release your artifacts 
 (in fact, it is sometimes impossible due to various limitations), 
 we also strongly encourage you to share them with the community
 even if they are not open-source.

 You can release them as an auxiliary material in Digital Libraries
 or use your institutional repository
 and various public services for code and data sharing.

 <p>
 <i>Even accepted artifacts may have some unforeseen behavior and limitations
 discovered during evaluation. Now you have a chance to add related notes 
 in the Artifact Appendix as a future work.</i>.

<!-------------------------------------------------------------------------------------------->
<p>
<h1><a name="examples"><u>A few artifact examples from the past conferences, workshops and journals</u></a></h1>

<ul>
 <li>
  <span style="color:#af0000">"Software Prefetching for Indirect Memory Accesses", CGO 2017, <b>dividiti award for the portable and customizable CK-based workflow</b> (<a href="https://github.com/SamAinsworth/reproduce-cgo2017-paper">Sources at GitHub</a>, <a href="$#ck_root_page_url#$resources/paper-with-distinguished-ck-artifact-and-ae-appendix-cgo2017.pdf">PDF with AE appendix</a>, <a href="https://github.com/SamAinsworth/reproduce-cgo2017-paper/files/618737/ck-aarch64-dashboard.pdf">CK dashboard snapshot</a>)</span>
 </li>
 <li>
  <span style="color:#af0000">"Optimizing Word2Vec Performance on Multicore Systems", IA3 at Computing 2017, <b>dividiti award for the portable and customizable CK-based workflow</b> (<a href="https://github.com/vasupsu/IA3_Paper16_ArtifactEvaluation">Sources at GitHub</a>, <a href="https://dl.acm.org/citation.cfm?doid=3149704.3149768">PDF with AE appendix</a>)</span>
 </li>
 <li>
  "Self-Checkpoint: An In-Memory Checkpoint Method Using Less Space and its Practice on Fault-Tolerant HPL", PPoPP 2017 (example of a public evaluation via HPC and supercomputer mailing lists: <a href="https://github.com/thu-pacman/self-checkpoint/issues/1">GitHub discussions</a>)
 </li>
 <li>
  "Lift: A Functional Data-Parallel IR for High-Performance GPU Code Generation", CGO 2017 (example of a public evaluation with a bug fix: <a href="https://gitlab.com/michel-steuwer/cgo_2017_artifact/issues/1">GitLab discussions</a>,
    example of a paper with AE Appendix and a stamp: <a href="https://github.com/michel-steuwer/publications/raw/master/2017/CGO-2017.pdf">PDF</a>,
    CK workflow for this artifact: <a href="https://github.com/lift-project/ck-lift">GitHub</a>,
    CK concepts: <a href="https://michel-steuwer.github.io/About-CK">blog</a>)
 </li>
 <li>
  "Gunrock: A High-Performance Graph Processing Library on the GPU", PPoPP 2016 (<a href="http://arxiv.org/pdf/1501.05387v6.pdf">PDF with AE appendix</a> and <a href="https://github.com/gunrock/gunrock">GitHub</a>)
 </li>
 <li>
  "GEMMbench: a framework for reproducible and collaborative benchmarking of matrix multiplication", ADAPT 2016 (example of a <a href="http://github.com/ctuning/ck/wiki">CK</a>-powered <a href="https://github.com/dividiti/gemmbench">artifact</a> </a> reviewed and validated by the community via <a href="https://www.reddit.com/r/adaptworkshop/comments/3sngox/adapt16_submission_gemmbench_a_framework_for/">Reddit</a>)
 </li>
 <li>
  "Integrating algorithmic parameters into benchmarking and design space exploration in dense 3D scene understanding", PACT 2016 (example of <a href="http://cknowledge.org/repo/web.php?template=cknowledge&wcid=208c21b837924601:2d41f89bcf32d4d4:3b1b261d30f3934a">interactive graphs</a> and <a href="http://github.com/ctuning/reproduce-pamela-project">artifacts</a> in the <a href="">Collective Knowledge</a> format)
 </li>
 <li>
  "Polymer: A NUMA-aware Graph-structured Analytics Framework", PPoPP 2015 (<a href="https://github.com/realstolz/polymer">GitHub</a> and <a href="http://ipads.se.sjtu.edu.cn/projects/polymer.html">personal web page</a>)
 </li>
 <li>
  "A graph-based higher-order intermediate representation", CGO 2015 (<a href="https://anydsl.github.io">GitHub</a>)
 </li>
 <li>
  "MemorySanitizer: fast detector of uninitialized memory use in C++", CGO 2015 (<a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43308.pdf">added to <a href="http://llvm.org">LLVM</a></a>)
 </li>
 <li>
  "Predicate RCU: an RCU for scalable concurrent updates", PPoPP 2015 (<a href="https://bitbucket.org/mayaarl/predicatercu">BitBucket</a>)
 </li>
 <li>
  "Low-Overhead Software Transactional Memory with Progress Guarantees and Strong Semantics", PPoPP 2015 (<a href="http://sourceforge.net/p/jikesrvm/research-archive/46/">SourceForge</a> and <a href="http://sourceforge.net/p/jikesrvm">Jikes RVM</a>)
 </li>
 <li>
  "More than You Ever Wanted to Know about Synchronization", PPoPP 2015 (<a href="https://github.com/gramoli/synchrobench">GitHub</a>)
 </li>
 <li>
  "Roofline-aware DVFS for GPUs", ADAPT 2014 (<a href="http://dl.acm.org/citation.cfm?doid=2553062.2553067">ACM DL</a>, <a href="http://cknowledge.org/repo/web.php?wcid=876bf92b1409cb46:26177154df5a20ef">Collective Knowledge repository</a>)
 </li>
 <li>
  "Many-Core Compiler Fuzzing", PLDI 2015 (example of an <a href="https://github.com/ctuning/ck/wiki/Getting_started_guide_clsmith">artifact</a> with a <a href="http://github.com/ctuning/ck/wiki/Portable-workflows">CK-based</a> experimental workflow and <a href="http://cknowledge.org/repo/web.php?wcid=bc0409fb61f0aa82:1b437e72c74fe782">live results</a>)
 </li>
</ul>

<!-------------------------------------------------------------------------------------------->
<p>
<h1><a name="archive"><u>Methodology archive</u></a></h2>

We keep track of the past submission and reviewing methodology to let readers 
understand which one was used in the papers with the evaluated artifacts.

<ul>
 <li><b>V20171101 (CGO'18/PPoPP'18)</b>: 
  <a href="$#ck_url_template_pull#$templates/ae-20170622.tex">LaTeX template</a>,
  <a href="$#ck_root_page_url#$submission-20171101$#ck_page_suffix#$">submission guide</a>,
  <a href="$#ck_root_page_url#$reviewing-20171101$#ck_page_suffix#$">reviewing guide</a>
 <li><b>V20170414 (PACT'17)</b>: 
  <a href="$#ck_url_template_pull#$templates/ae-20160509.tex">LaTeX template</a>,
  <a href="$#ck_root_page_url#$submission-20170414$#ck_page_suffix#$">submission guide</a>,
  <a href="$#ck_root_page_url#$reviewing-20170414$#ck_page_suffix#$">reviewing guide</a>
 <li><b>V20161020 (PPoPP'17/CGO'17)</b>: 
  <a href="$#ck_url_template_pull#$templates/ae-20160509.tex">LaTeX template</a>,
  <a href="$#ck_root_page_url#$submission-20161020$#ck_page_suffix#$">submission guide</a>,
  <a href="$#ck_root_page_url#$reviewing-20161020$#ck_page_suffix#$">reviewing guide</a>
 <li><b>V20160509 (PACT'16)</b>: 
  <a href="$#ck_url_template_pull#$templates/ae-20160509.tex">LaTeX template</a>,
  <a href="$#ck_root_page_url#$submission-20160509$#ck_page_suffix#$">submission guide</a>,
  <a href="$#ck_root_page_url#$reviewing-20160509$#ck_page_suffix#$">reviewing guide</a>
 <li><b>V20151015 (PPoPP'16/CGO'16/ADAPT'16)</b>: 
  <a href="$#ck_url_template_pull#$templates/ae-20151015.tex">LaTeX template</a>,
  <a href="$#ck_root_page_url#$submission-20151015$#ck_page_suffix#$">submission guide</a>,
  <a href="$#ck_root_page_url#$reviewing-20151015$#ck_page_suffix#$">reviewing guide</a>
</ul>

<br>
 <center>
 <i><h2>Thank you for participating in Artifact Evaluation!</h2></i>
 </center>
<br>
